{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the pre-trained Faster R-CNN model with ResNet-50 backbone\n",
        "model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Define the transformation pipeline to preprocess frames\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Input and output video file paths\n",
        "input_file = 'ball.mp4'\n",
        "output_file = 'output_video.mp4'\n",
        "\n",
        "# Open mp4\n",
        "cap = cv2.VideoCapture(input_file)\n",
        "\n",
        "# Get frame rate, width, and height of ball.mp4\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Initialize the video writer for the output file\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Process each frame in the video\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # If frame was not successfully read, exit the loop\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Preprocess the frame by converting it to a tensor\n",
        "    frame_tensor = transform(frame).unsqueeze(0)\n",
        "\n",
        "    # Forward pass through the model and get predictions\n",
        "    with torch.no_grad():\n",
        "        predictions = model(frame_tensor)\n",
        "\n",
        "    # Extract boxes & scores from the predictions\n",
        "    boxes = predictions[0]['boxes']\n",
        "    scores = predictions[0]['scores']\n",
        "\n",
        "    # Filter low-confidence detections based on a threshold\n",
        "    threshold = 0.5\n",
        "    boxes = boxes[scores > threshold]\n",
        "\n",
        "    # Draw bounding boxes and centroids on the frame\n",
        "    for box in boxes:\n",
        "        # Convert the box coordinates to integers\n",
        "        box = box.detach().cpu().numpy().astype(np.int32)\n",
        "\n",
        "        # Draw a rectangle around the detected object\n",
        "        cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
        "\n",
        "        # Calculate the centroid coordinates of the box\n",
        "        centroid_x = (box[0] + box[2]) // 2\n",
        "        centroid_y = (box[1] + box[3]) // 2\n",
        "\n",
        "        # Draw a circle at the centroid to represent it\n",
        "        cv2.circle(frame, (centroid_x, centroid_y), 3, (0, 255, 0), -1)\n",
        "\n",
        "    # Write the frame to the output video\n",
        "    out.write(frame)\n",
        "\n",
        "# Free used resources\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Close any open windows from the code\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "SIJF-3Mesb_s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}